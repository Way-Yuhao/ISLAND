"""
Interpolates the TOA Brightness Temperature (B10 band from Landsat 8/9)
"""
import os
import os.path as p
import datetime as dt
from datetime import timedelta
import pandas as pd
from tqdm import tqdm
from config import *
from util.filters import *
from util.helper import deprecated, rprint, yprint
from interpolators.interpolator import BaseInterpolator


class BT_Interpolator(BaseInterpolator):

    def __init__(self, root, target_date=None, no_log=False):
        super().__init__(root, target_date, no_log)
        # self.bt_path = p.join(root, 'bt_series')
        self.interp_mode = 'bt'
        self.get_target(target_date)
        return

    # def get_frame(self, frame_date, mode='bt'):
    #     """
    #     Loads an image corresponding to a specified date.
    #     :param frame_date:
    #     :return: ndarray for the target bt image
    #     """
    #     if mode in ['bt', 'bt_series']:
    #         mode = 'bt_series'
    #     elif mode == 'cloud':
    #         pass
    #     elif mode == 'shadow':
    #         pass
    #     else:
    #         raise ValueError(f'Unexpected mode encountered. Got {mode}')
    #     parent_dir = p.join(self.root, mode)
    #     img_files = os.listdir(parent_dir)
    #     target_file = [f for f in img_files if frame_date in f and 'nlcd' not in f]
    #     target_file = [f for f in target_file if 'aux' not in f]  # files generated by geemap visualization
    #     if len(target_file) == 1:
    #         frame = cv2.imread(p.join(parent_dir, target_file[0]), -1)
    #     elif len(target_file) == 0:
    #         raise FileNotFoundError(f'Target date {frame_date} does not exist in {parent_dir}')
    #     else:
    #         raise FileExistsError(
    #             f'Multiple ({len(target_file)}) files found for target date {frame_date} in {parent_dir}')
    #     # clean up
    #     frame[np.isnan(frame)] = -1
    #     frame[np.isinf(frame)] = -1
    #     if np.any(frame == -1):
    #         pass
    #     return frame

    # def get_target(self, target_date):
    #     """
    #     get target bt image and build valid mask. Pixel values of valid mask is false where there is a registration
    #     error or there is a cloud/cloud shadow for the ground truth image. Notice that such cloud/cloud shadow mask is
    #     imperfect.
    #     :param target_date:
    #     :return:
    #     """
    #     self.target = self.get_frame(frame_date=target_date)
    #     # clean up target (invalid pixels due to registration)
    #     # self.target_valid_mask = np.ones_like(self.target, dtype=np.bool_)
    #     # self.target_valid_mask[self.target < 0] = False
    #     self.target_valid_mask = self.build_valid_mask()
    #     self.target[self.target < 0] = 0  # overwrite np.nan or -inf with 0

    # def build_valid_mask(self, alt_date=None):
    #     """
    #     computers a binary bitmask representing the validity of pixel values for a BT map on a given day. Pixels marked
    #     as True are valid pixels. Valid pixels satisfy (1) no cloud, and (2) no cloud shadow, and (3) bt reading greater
    #     than 0 K.
    #     :param alt_date:
    #     :return:
    #     """
    #     if alt_date is None:  # using default target date
    #         bt_img = self.target.copy()
    #         cloud_img = self.get_frame(frame_date=self.target_date, mode='cloud')
    #         shadow_img = self.get_frame(frame_date=self.target_date, mode='shadow')
    #     else:
    #         bt_img = self.get_frame(frame_date=alt_date, mode='bt_series')
    #         cloud_img = self.get_frame(frame_date=alt_date, mode='cloud')
    #         shadow_img = self.get_frame(frame_date=alt_date, mode='shadow')
    #     valid_mask = cloud_img + shadow_img
    #     valid_mask = ~np.array(valid_mask, dtype=np.bool_)
    #     valid_mask[bt_img < 0] = False
    #     return valid_mask

    # def get_nlcd(self):
    #     """
    #     Load a pre-aligned NLCD land cover map corresponding to a target LANDSAT temperature map
    #     :return:
    #     """
    #     if self.ablation_no_nlcd:  # ablation mode
    #         files = os.listdir(self.root)
    #         nlcds = [f for f in files if 'nlcd' in f]
    #         nlcd_rgb_path = p.join(self.root, [f for f in nlcds if 'color' in f][0])
    #         nlcd_path = p.join(self.root, [f for f in nlcds if 'color' not in f][0])
    #         nlcd = cv2.imread(nlcd_path, -1)
    #         nlcd = np.ones_like(nlcd) * 11
    #         nlcd_rgb = nlcd
    #     else:  # regular mode
    #         files = os.listdir(self.root)
    #         nlcds = [f for f in files if 'nlcd' in f and '.tif' in f]
    #         nlcds = [f for f in nlcds if '._' not in f]
    #         nlcd_rgb_path = p.join(self.root, [f for f in nlcds if 'color' in f][0])
    #         nlcd_path = p.join(self.root, [f for f in nlcds if 'color' not in f][0])
    #         nlcd = cv2.imread(nlcd_path, -1)
    #         nlcd_rgb = cv2.imread(nlcd_rgb_path, -1)
    #         nlcd_rgb = cv2.cvtColor(nlcd_rgb, cv2.COLOR_BGR2RGB)
    #     assert nlcd is not None and nlcd_rgb is not None
    #     return nlcd, nlcd_rgb

    # def correct_nlcd_key_error(self, to_key=11):
    #     """
    #     Arbitrarily assign pixels with values 0 with a specified key.
    #     These pixels are usually in marine regions and are presumed to be open water
    #     :param to_key: default is 11, open water
    #     :return:
    #     """
    #     nlcd_ = self.nlcd.copy()
    #     unlabeled_pixels = nlcd_ == 0
    #     error_pixel_count = np.count_nonzero(unlabeled_pixels)
    #     # error_pixel_count = nlcd_.size - np.count_nonzero(nlcd_)
    #     if error_pixel_count > 0:
    #         yprint(f'{error_pixel_count} pixels NLCD pixels are not labeled. Replacing with {to_key}')
    #         nlcd_[nlcd_ == 0] = to_key
    #         self.nlcd = nlcd_
    #     return

    # def _clean(self, img, mask=None):
    #     """
    #     Replace pixel values with 0 for all locations where valid mask is False. By default, it uses
    #     target_valid_mask attribute. Masks image in place AND returns masked image.
    #     :param img:
    #     :return:
    #     """
    #     if mask is None:
    #         if self.target_valid_mask is None:
    #             raise AttributeError
    #         else:
    #             mask = self.target_valid_mask
    #     img[~mask] = 0
    #     return img

    # def display(self, img, error_cbar=False, msg='', xlabel_text=None):
    #     if type(img) is np.ndarray:
    #         pass
    #     elif img in ['gt', 'target', 't']:
    #         img = self.target
    #         msg = 'Ground Truth'
    #     elif img in ['occluded', 'o']:
    #         img = self.occluded_target
    #         msg = 'Occluded'
    #     elif img in ['reconst', 'r']:
    #         img = self.reconstructed_target
    #         msg = 'Reconstructed'
    #     else:
    #         raise AttributeError('Unknown image to display specified. Must be either a reserved string like gt, '
    #                              'occluded, reconst, error, or an np.ndarray object.')
    #     assert img is not None
    #     if error_cbar:
    #         max_, min_ = 15, -15
    #         cmap_ = 'seismic'
    #     else:
    #         min_ = img[img > 250].min()
    #         max_ = min(330, img.max())
    #         cmap_ = 'magma'
    #     plt.imshow(img, cmap=cmap_, vmin=min_, vmax=max_)
    #     plt.xlabel(xlabel_text)
    #     plt.title(f'{msg} Brightness Temperature on {self.target_date}')
    #     plt.colorbar(label='BT(Kelvin)')
    #     plt.show()
    #     return 0

    # @deprecated  # reason: clean
    # def display_target(self, mode=None, img=None, text=None):
    #     """
    #     Displays a plot via matplotlib for the desired matrix
    #     :param mode:
    #     :param img:
    #     :param text:
    #     :return:
    #     """
    #     # plt.figure(figsize=(20, 20))
    #     if mode == 'gt' and img is None:
    #         img = self.target
    #         msg = 'Ground Truth'
    #     elif mode == 'occluded' and img is None:
    #         img = self.occluded_target
    #         assert self.occluded_target is None
    #         msg = 'Occluded'
    #     elif mode == 'reconst' and img is None:
    #         img = self.reconstructed_target
    #         assert self.reconstructed_target is not None
    #         msg = 'Reconstructed'
    #     elif mode == 'error' and img is None:
    #         if self.reconstructed_target is None:
    #             img = self._clean(self.occluded_target - self.target)
    #             msg = 'Error (occluded)'
    #         else:
    #             img = self._clean(self.reconstructed_target - self.target)
    #             msg = 'Error (reconstructed)'
    #     elif img is not None:  # img to display is included in args
    #         if img.max() == img.min():
    #             print('Empty image invoked to display. Skipped.')
    #             return -1
    #         msg = 'Custom'
    #     else:
    #         raise AttributeError('Unknown display mode. Choose among {gt, occluded, reconst}')
    #     # matplotlib.use('macosx')
    #     if mode != 'error':
    #         min_ = img[img > 250].min()
    #         max_ = min(330, img.max())
    #         cmap_ = 'magma'
    #     else:
    #         # max_delta = max(img.max(), -img.min())
    #         # max_ = max_delta
    #         # min_ = -max_delta
    #         max_, min_ = 15, -15  # FIXME
    #         cmap_ = 'seismic'
    #     plt.imshow(img, cmap=cmap_, vmin=min_, vmax=max_)
    #     plt.xlabel(text)
    #     plt.title(f'{msg} Brightness Temperature on {self.target_date}')
    #
    #     plt.colorbar(label='BT(Kelvin)')
    #     plt.show()
    #     return 0

    # def add_occlusion(self, fpath=None, use_true_cloud=False):
    #     """
    #     Adds synthetic occlusion according to a bitmap. The occluded region will have pixel values of 0
    #     :param fpath: path to the occlusion bitmap file. A synthetic occlusion bitmask will be generated,
    #     where occluded regions will have pixel values of True (1).
    #     :return: fractions of pixels being occluded
    #     """
    #     if fpath is not None and use_true_cloud is False:
    #         assert p.exists(fpath), f'{fpath} does not exist.'
    #         self.synthetic_occlusion = cv2.imread(fpath, -1)
    #         self.synthetic_occlusion = np.array(self.synthetic_occlusion, dtype=np.bool_)  # wrap in binary form
    #         assert (self.synthetic_occlusion is not None)
    #         occlusion = self.synthetic_occlusion
    #         self.occlusion_id = fpath[-12:-4]
    #     elif fpath is None and use_true_cloud is True:
    #         if self.target_valid_mask is None:
    #             self.target_valid_mask = self.build_valid_mask()
    #         occlusion = ~self.target_valid_mask
    #         self.synthetic_occlusion = occlusion  # FIXME
    #         self.occlusion_id = self.target_date
    #     else:
    #         raise AttributeError()
    #     self.occluded_target = self.target.copy()
    #     self.occluded_target[occlusion] = 0
    #     px_count = occlusion.shape[0] * occlusion.shape[1]
    #     occlusion_percentage = np.count_nonzero(occlusion) / px_count
    #     # print(f"{occlusion_percentage:.3%} of pixels added arbitrary occlusion"
    #     return occlusion_percentage

    # def calc_loss(self, metric='mae', print_=False, entire_canvas=False):
    #     """
    #     calculates the mean absolute error (MAE) over the synthetically occluded area
    #     :return:
    #     """
    #
    #     if self.reconstructed_target is None:
    #         print('No reconstruction map found. Calculating loss on initial occluded image')
    #         a, b = self.target, self.occluded_target
    #     else:
    #         a, b = self.target, self.reconstructed_target
    #
    #     if metric == "mae":
    #         error_map = np.abs(a - b)
    #     elif metric == 'mse':
    #         error_map = np.square(a - b)
    #     else:
    #         raise AttributeError(f'Unknown loss function encountered: {metric}. ')
    #     error_map = self._clean(error_map)
    #     if not entire_canvas:  # by default, only calculate loss on synthetic occluded regions
    #         loss = np.sum(error_map) / np.count_nonzero(self.synthetic_occlusion)
    #     else:  # calculate loss on entire canvas
    #         loss = np.average(error_map)
    #
    #     if print_:
    #         print(f'{metric} loss = {loss:.3f}')
    #     return loss

    # def clear_outputs(self):
    #     self.reconstructed_target = None
    #     return

    # def save_output(self, msg=''):
    #     """
    #     Saves a NumPy array (unscaled) and a PyPlot (scaled for visualization) file for reconstruction
    #     result. Requires reconstruction result to exist.
    #     :return: None
    #     """
    #     if msg != '':
    #         msg = f'_{msg}'
    #     if self.reconstructed_target is None:
    #         raise ValueError('Reconstruction result does not exist. Cannot save image output')
    #     else:
    #         try:
    #             img = self.reconstructed_target
    #             # save numpy array
    #             output_filename = f'reconst_t{self.target_date}_syn{self.occlusion_id}_ref{self.ref_frame_date}{msg}'
    #             np.save(p.join(self.output_path, output_filename),
    #                     img)  # float32 recommended. float16 only saves 1 decimal
    #
    #             # save pyplot
    #             # min_ = img[img > 250].min()
    #             # max_ = min(330, img.max())
    #
    #             min_ = 270
    #             max_ = 330
    #
    #             cmap_ = 'magma'
    #             plt.imshow(img, cmap=cmap_, vmin=min_, vmax=max_)
    #             plt.title(f'Reconstructed Brightness Temperature on {self.target_date}')
    #             plt.colorbar(label='BT(Kelvin)')
    #             output_filename = f'reconst_t{self.target_date}_syn{self.occlusion_id}_ref{self.ref_frame_date}{msg}.png'
    #             plt.savefig(p.join(self.output_path, output_filename))
    #             print('Pyplot vis saved to ', output_filename)
    #         except ValueError as e:
    #             rprint(f'ERROR: {e}.\n Current image not saved.')
    #         plt.close()
    #     return

    ######################### interpolation schemes  #########################

    def compute_spatio_temporal_weight(self):
        """
        Return weight w to be used for spatial channel. (1 - w) will be used for temporal
        :return:
        """
        if self.synthetic_occlusion is None:
            raise AttributeError()
        px_count = self.synthetic_occlusion.shape[0] * self.synthetic_occlusion.shape[1]
        occlusion_percentage = np.count_nonzero(self.synthetic_occlusion) / px_count
        return 1 - occlusion_percentage

    def run_interpolation(self, spatial_global_cutoff=.5):
        print('Running spatial & temporal channel...')

        px_count = self.synthetic_occlusion.shape[0] * self.synthetic_occlusion.shape[1]
        occlusion_percentage = np.count_nonzero(self.synthetic_occlusion) / px_count
        print(f'occlusion percentage (real + synth) = {occlusion_percentage:.3f}')

        # self.reconstructed_target = self.occluded_target.copy()
        # self.save_output('occluded')
        # self.reconstructed_target = None

        # TODO: local gaussian for all?
        if occlusion_percentage > .99:
            # remote these
            self.reconstructed_target = self.occluded_target.copy()
            self.save_timelapse_frame(suffix='occluded')
            self.reconstructed_target = None

            print('Encountered 100% cloudy frame. Skipped.')
            self.reconstructed_target = np.zeros_like(self.occluded_target)
            self.save_timelapse_frame(suffix='spatial')
            self.save_timelapse_frame(suffix='temporal')
            self.save_timelapse_frame(suffix='st')
        else:
            self.reconstructed_target = None
            if occlusion_percentage < .5:
                self._nlm_local(f=75)  # spatial, local gaussian
            else:
                self._nlm_global()  # spatial, global rectangular
            self.save_timelapse_frame(suffix='spatial')
            reconst_spatial = self.reconstructed_target.copy()
            assert reconst_spatial is not None

            self.reconstructed_target = None
            try:
                self.temporal_interp_multi_frame(num_frames=3, max_delta_cycle=2, max_cloud_perc=.1)
            except ArithmeticError:
                yprint('Retrying temporal reference with max_delta_cycle = 4')
                try:
                    self.temporal_interp_multi_frame(num_frames=3, max_delta_cycle=4, max_cloud_perc=.1)
                except ArithmeticError:
                    yprint('Retrying temporal reference with max_delta_cycle = 4 and max_cloud_prec = .2')
                    self.temporal_interp_multi_frame(num_frames=3, max_delta_cycle=4, max_cloud_perc=.2)
            # assume temporal computation is successful
            self.save_timelapse_frame(suffix='temporal')
            reconst_temporal = self.reconstructed_target.copy()
            assert reconst_temporal is not None

            self.reconstructed_target = None
            w_spatial = self.compute_spatio_temporal_weight()
            w_temporal = 1 - w_spatial
            # self.reconstructed_target = (reconst_spatial + reconst_temporal) / 2
            self.reconstructed_target = w_spatial * reconst_spatial + w_temporal * reconst_temporal
            self.save_timelapse_frame(suffix='st')
        return

    def spatial_interp(self, f=None):
        self._nlm_local(f)
        # self._nlm_global()

    def _nlm_global(self):
        """
        spatial channel, global rectangular filter. May throw Value Error when there does not exist any
        replacement candidate for some class in the entire canvas.
        :return:
        """
        print(f"SPATIAL FILTER: global filter")
        self.reconstructed_target = self.occluded_target.copy()

        px_count = np.count_nonzero(self.occluded_target)
        default_avg_temp = np.sum(self.occluded_target) / px_count  # global, class-agnostic

        for c, _ in NLCD_2019_META['lut'].items():
            c = int(c)
            temp_for_c = self.occluded_target.copy()
            temp_for_c[self.nlcd != c] = 0  # remove other classes

            # show map for each class
            # plt.imshow(temp_for_c)
            # plt.title(c)
            # plt.show()

            px_count = np.count_nonzero(temp_for_c)
            avg_temp = np.sum(temp_for_c) / px_count if px_count else None

            # pixels corresponding to current class and requiring filling values
            replacement_bitmap = np.zeros_like(self.occluded_target, dtype=np.bool_)
            replacement_bitmap[self.nlcd == c] = True
            replacement_bitmap[self.synthetic_occlusion == 0] = False

            if avg_temp is not None and np.any(replacement_bitmap):  # requires in-paint, data available
                self.reconstructed_target[replacement_bitmap] = avg_temp
            elif avg_temp is None and np.any(replacement_bitmap):  # requires in-paint, data unavailable
                # raise ValueError(f'Unable to acquire average temperature for class {c}')
                yprint(f'Unable to acquire average temperature for class {c}. Default to global average.')
                self.reconstructed_target[replacement_bitmap] = default_avg_temp

    def _nlm_local(self, f=100):
        """
        spatial channel, local gaussian filter with kernel size of f
        :param f: kernel size, in pixels
        :return:
        """
        assert f is not None, "filter size cannot be None"
        print(f"SPATIAL FILTER: local gaussian filter with f={f}")
        self.reconstructed_target = self.occluded_target.copy()
        x_length, y_length = self.occluded_target.shape

        temp_class_c = {}  # temperature map for each class
        # average temperature for all pixels under each class
        avg_temp = {}
        for c, _ in NLCD_2019_META['lut'].items():
            c = int(c)
            cur = self.occluded_target.copy()
            cur[self.nlcd != c] = 0  # remove other classes
            temp_class_c[c] = cur
            px_counts = np.count_nonzero(temp_class_c[c])
            avg_temp[c] = np.sum(temp_class_c[c]) / px_counts if px_counts != 0 else None

        print("processing missing pixels...")
        no_local_data_counter = 0
        pbar = tqdm(total=np.count_nonzero(self.synthetic_occlusion), position=0)
        x_cord, y_cord = np.nonzero(self.synthetic_occlusion)
        for x, y in zip(x_cord, y_cord):
            c = self.nlcd[x, y]
            # rectangular kernel
            x_left, x_right = max(0, x - f), min(x_length - 1, x + f)
            y_left, y_right = max(0, y - f), min(y_length - 1, y + f)
            local_region = temp_class_c[c][x_left: x_right + 1, y_left: y_right + 1]
            local_region_bin = np.array(local_region, dtype=np.bool_)
            if np.any(local_region_bin):  # data available in local region
                kernel = gkern(canvas=local_region.shape, center=(x - x_left, y - y_left), sig=f / 2)
                kernel[~local_region_bin] = 0
                est_temp = np.sum(local_region * kernel) / np.sum(kernel)
                self.reconstructed_target[x, y] = est_temp
            else:  # data unavailable in local region
                self.reconstructed_target[x, y] = avg_temp[c]
                no_local_data_counter += 1
            pbar.update()
        pbar.close()
        print(f'{no_local_data_counter} pixels ({no_local_data_counter / (x_length * y_length):.5%}) '
              f'used global calculations')

    def temporal_interp_multi_frame(self, num_frames, max_delta_cycle, max_cloud_perc):
        assert num_frames in range(1, 11)  # between 1 and 11 frames
        print(f'Looking for at most {num_frames} reference frame candidates subject to')
        print('\tdelta cycle < ', max_delta_cycle)
        print('\tcloud coverage percentage < ', max_cloud_perc)

        # flist = os.listdir(p.join(self.root, 'cloud'))
        # flist = [f for f in flist if 'tif' in f]
        # ref_dates_str = [f[11:-4] for f in flist]  # a list of all reference frame dates

        ref_dates_str = self.metadata['date'].values.tolist()
        ref_occlusion_perc = self.metadata['cloud_percentage'].values.tolist()
        ref_dates = [dt.datetime.strptime(str(d), '%Y%m%d').date() for d in ref_dates_str]
        target_date = dt.datetime.strptime(str(self.target_date), '%Y%m%d').date()

        days_delta, same_year_deltas, ref_percs = [], [], []
        for ref_date in ref_dates:
            days_delta.append(abs((target_date - ref_date).days))
            try:
                ref_same_year = ref_date.replace(year=target_date.year)
            except ValueError:  # leap year
                yprint('Encountered lead year. Using the previous day as reference.')
                ref_same_year = (ref_date - timedelta(days=1)).replace(year=target_date.year)
            same_year_delta = abs((target_date - ref_same_year).days)
            same_year_deltas.append(min(same_year_delta, 365 - same_year_delta))

        df = pd.DataFrame(ref_dates_str, columns=['ref_dates'])  # a list of all candidates for reference frames
        df['same_year_delta'] = same_year_deltas
        df['days_delta'] = days_delta
        df['ref_percs'] = ref_occlusion_perc

        df = df.loc[df['days_delta'] != 0]  # remove target frame itself
        df = df.loc[df['same_year_delta'] < max_delta_cycle * 16 + 1]  # filter by max delta cycle
        df = df.loc[df['ref_percs'] < max_cloud_perc]  # filter by max cloud coverage
        df = df.sort_values(by=['days_delta'])
        # print(df)
        print(f'Found {len(df.index)} candidate frames that satisfy conditions:')
        if df.empty:
            yprint('No candidate reference frames satisfy conditions above. Mission aborted.')
            raise ArithmeticError()
        if num_frames < len(df.index):
            df = df.iloc[:num_frames]
        print(f'Selected {len(df.index)} frames closest to target frame in time:')
        print(df)
        selected_ref_dates = df['ref_dates'].values
        reconst_imgs = []

        for d in selected_ref_dates:
            self.temporal_interp(ref_frame_date=d)
            reconst_imgs.append(self.reconstructed_target)
            # self.save_output()
            self.reconstructed_target = None

        # blended image is the average of all reconstructed images, with equal weights
        blended_img = np.zeros_like(reconst_imgs[0])
        for i in reconst_imgs:
            blended_img += i
        blended_img /= len(reconst_imgs)
        self.reconstructed_target = blended_img
        # self.save_output()

    def temporal_interp(self, ref_frame_date, global_threshold=.5):
        """
        performs temporal interpolation with respect to one specified reference frame. This method does not introduce
        synthetic occlusion to reference frame.
        :param global_threshold: if the cloud coverage percentage of reference frame is above this threshold,
               then use global filter
        :param ref_frame_date:
        :return: real occlusion percentage for the reference frame
        """
        # load one image from the past
        target_frame = self.occluded_target.copy()
        reconst_img = np.zeros_like(target_frame, dtype=np.float32)
        target_avgs, past_avgs = {}, {}  # mean temperature (scalar) for all pixels in each class

        self.ref_frame_date = ref_frame_date
        ref_frame = self.get_frame(self.ref_frame_date, mode=self.interp_mode)

        ref_interp = BT_Interpolator(root=self.root, target_date=self.ref_frame_date)
        ref_occlusion_percentage = ref_interp.add_occlusion(use_true_cloud=True)
        if ref_occlusion_percentage <= global_threshold:  # use local gaussian
            ref_interp._nlm_local(f=75)
            if np.isnan(ref_interp.reconstructed_target).any():
                ref_interp.reconstructed_target = None
                ref_interp._nlm_global()
        else:  # use global rectangular
            ref_interp._nlm_global()
        complete_ref_frame = ref_interp.reconstructed_target.copy()  # pre-processed ref frame, spatially complete

        for c, _ in NLCD_2019_META['lut'].items():
            c = int(c)
            past_c = ref_frame.copy()
            target_c = target_frame.copy()
            complete_past_c = complete_ref_frame.copy()
            past_c[self.nlcd != c] = 0
            complete_past_c[self.nlcd != c] = 0
            target_c[self.nlcd != c] = 0

            target_avg_pixels = target_c[np.where(target_c != 0)]
            target_avg_pixels = target_avg_pixels[target_avg_pixels >= 0]  # clean up invalid pixels
            past_avg_pixels = past_c[np.where(past_c != 0)]
            past_avg_pixels = past_avg_pixels[past_avg_pixels >= 0]  # clean up invalid pixels
            if len(target_avg_pixels) != 0:
                target_avgs[c] = np.average(target_avg_pixels)
            if len(past_avg_pixels) != 0:
                past_avgs[c] = np.average(past_avg_pixels)

            # build reconstruction image class by class
            if c in target_avgs and c in past_avgs:
                # compensated_past_c = past_c.copy()  # with no spatial pre-processing on reference frame
                compensated_past_c = complete_past_c.copy()  # with spatial pre-processing on reference frame
                compensated_past_c[compensated_past_c != 0] += target_avgs[c] - past_avgs[c]
                reconst_img += compensated_past_c
            else:
                # raise AttributeError(c)  # TODO
                pass

        self.reconstructed_target = np.zeros_like(self.occluded_target)
        self.reconstructed_target[self.synthetic_occlusion] = reconst_img[self.synthetic_occlusion]
        self.reconstructed_target[~self.synthetic_occlusion] = self.occluded_target[~self.synthetic_occlusion]

        del ref_interp
        return ref_occlusion_percentage

    @deprecated
    def temporal_interp_cloud(self, ref_frame_date, ref_syn_cloud_date):
        """
        Performs temporal interpolation after applying synthetic cloud to reference frame.
        Requires cloud-free reference frame.
        :param ref_frame_date:
        :param ref_syn_cloud_date:
        :return: synthetic occlusion percentage of the past frame
        """
        # TODO: add cloud masking
        target_frame = self.occluded_target.copy()
        # target_frame = self._clean(target_frame)
        # load one image from the past
        self.ref_frame_date = ref_frame_date
        past_interp = BT_Interpolator(root=self.root, target_date=self.ref_frame_date)
        past_syn_occlusion_perc = past_interp.add_occlusion(fpath=p.join(past_interp.root, 'cloud',
                                                                         f'LC08_cloud_{ref_syn_cloud_date}.tif'))
        past_interp._nlm_global()
        past_frame = past_interp.reconstructed_target  # complete

        reconst_img = np.zeros_like(target_frame, dtype=np.float32)
        target_avgs, past_avgs = {}, {}  # mean temperature (scalar) for all pixels in each class
        for c, _ in NLCD_2019_META['lut'].items():
            c = int(c)
            past_c = past_frame.copy()
            target_c = target_frame.copy()
            past_c[self.nlcd != c] = 0
            target_c[self.nlcd != c] = 0

            target_avg_pixels = target_c[np.where(target_c != 0)]
            target_avg_pixels = target_avg_pixels[target_avg_pixels >= 0]  # clean up invalid pixels
            past_avg_pixels = past_c[np.where(past_c != 0)]
            past_avg_pixels = past_avg_pixels[past_avg_pixels >= 0]  # clean up invalid pixels
            if len(target_avg_pixels) != 0:
                target_avgs[c] = np.average(target_avg_pixels)
            if len(past_avg_pixels) != 0:
                past_avgs[c] = np.average(past_avg_pixels)

            # build reconstruction image class by class
            if c in target_avgs and c in past_avgs:
                compensated_past_c = past_c.copy()
                compensated_past_c[compensated_past_c != 0] += target_avgs[c] - past_avgs[c]
                reconst_img += compensated_past_c
            else:
                # raise AttributeError(c)  # TODO
                pass
        reconst_img = self._clean(reconst_img)
        self.reconstructed_target = reconst_img
        return past_syn_occlusion_perc

    #########################################################################################

    # def calc_avg_temp_for_class(self, c: int):
    #     assert str(c) in NLCD_2019_META['lut'], "ERROR: invalid NLCD class"
    #     temp_for_c = self.target.copy()
    #     temp_for_c[self.nlcd != c] = 0
    #
    #     px_count = np.count_nonzero(temp_for_c)
    #     avg_temp = np.sum(temp_for_c) / px_count
    #
    #     min_ = self.target[self.target > 250].min()
    #     max_ = min(330, self.target.max())
    #     plt.imshow(temp_for_c, cmap='magma', vmin=min_, vmax=max_)
    #     plt.title(f'Brightness Temperature on {self.target_date} for class {c}')
    #     plt.colorbar(label='BT(Kelvin)')
    #     plt.show()
    #
    #     return avg_temp, px_count

    # def calc_temp_per_class(self):
    #     overall_p_count = np.count_nonzero(self.target)
    #     for c, _ in NLCD_2019_META['lut'].items():
    #         t, p_count = self.calc_avg_temp_for_class(c=int(c))
    #         print(f'cLass {c} | average temp = {t:.2f} | freq = {p_count * 100 / overall_p_count: .2f}%')

    # @deprecated
    # def plot_scatter_class(self):
    #     plt.figure(figsize=(10, 5))
    #     i = 0
    #     for c, _ in NLCD_2019_META['lut'].items():
    #         c = int(c)
    #         temp_for_c = self.target.copy()
    #         temp_for_c[self.nlcd != c] = 0
    #         dp = temp_for_c[np.where(temp_for_c != 0)]
    #         if len(dp > 0):
    #             x = np.ones_like(dp) * i
    #             y_mean = np.average(dp)
    #             y_std = np.std(dp)
    #             plt.scatter(x=x, y=dp, s=3, c='#' + NLCD_2019_META['lut'][str(c)],
    #                         label=NLCD_2019_META['class_names'][str(c)])
    #             plt.errorbar(x=i, y=y_mean, yerr=y_std, fmt='.', color='black', capsize=3)
    #             i += 1
    #     plt.xlabel('NLCD Landcover Class')
    #     plt.ylabel('Brightness Temperature (K)')
    #     plt.xticks([])
    #     plt.title('Distribution of Brightness Temperature per Landcover Class')
    #     plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), markerscale=5)
    #     plt.tight_layout()
    #     plt.show()

    # def plot_violins(self, show=True, include_class_agnostic=False):
    #     plt.figure(figsize=(16, 5))
    #     df = pd.DataFrame({'class': [], 'bt': []})
    #     palette = []
    #     i = 0
    #     for c, _ in NLCD_2019_META['lut'].items():
    #         c = int(c)
    #         temp_for_c = self.target.copy()
    #         temp_for_c[self.nlcd != c] = 0
    #         dp = temp_for_c[np.where(temp_for_c != 0)]
    #         if len(dp > 0):
    #             x = len(dp) * [NLCD_2019_META['class_names'][str(c)] + f'\n({np.var(dp):.2f})']
    #             new_df = pd.DataFrame({'class': x, 'bt': dp})
    #             df = pd.concat([df, new_df], ignore_index=True)
    #             palette += ['#' + NLCD_2019_META['lut'][str(c)]]
    #             print(f'class = {x[0]}, var = {np.var(dp):.2f}')
    #         i += 1
    #     if include_class_agnostic:
    #         dp = self.target[np.where(self.target != 0)]
    #         x = len(dp) * ['All classes' + f'\n({np.var(dp):.2f})']
    #         new_df = pd.DataFrame({'class': x, 'bt': dp})
    #         df = pd.concat([df, new_df], ignore_index=True)
    #         palette += ['#FFFFFF']
    #         print(f'class = all, var = {np.var(dp):.2f}')
    #     ax = sns.violinplot(x='class', y='bt', data=df, palette=palette)
    #     ax.set_xticklabels(textwrap.fill(x.get_text(), 11) for x in ax.get_xticklabels())
    #     ax.yaxis.set_major_locator(MaxNLocator(integer=True))
    #     plt.xlabel('NLCD Land Cover Class', fontsize=18)
    #     plt.ylabel('Brightness Temperature (K)', fontsize=18)
    #     # plt.title('Distribution of Brightness Temperature per Landcover Class', fontsize=18)
    #     plt.tight_layout()
    #     if show:
    #         plt.show()

    # def add_random_occlusion(self, size, num_occlusions):
    #     assert size > 0
    #     assert num_occlusions > 0
    #
    #     max_iterations = 1000
    #     min_area_threshold = .9
    #     single_occlusion_px_size = size ** 2
    #
    #     max_h = self.target.shape[0] - size
    #     max_w = self.target.shape[1] - size
    #
    #     if self.target_valid_mask is None:
    #         self.target_valid_mask = self.build_valid_mask()
    #     real_occlusion = ~self.target_valid_mask.copy()
    #     all_occlusion_mask = real_occlusion.copy()  # np.bool
    #     i, occlusions_added = 0, 0
    #     while True:
    #         new_occlusion = np.zeros_like(all_occlusion_mask)  # np.bool
    #         h = np.random.randint(0, max_h)
    #         w = np.random.randint(0, max_w)
    #         new_occlusion[h: h + size, w: w + size] = True
    #         occlusion_be_to_added = np.logical_and(new_occlusion, ~all_occlusion_mask)  # union
    #         # print(np.count_nonzero(occlusion_be_to_added))
    #         if np.count_nonzero(occlusion_be_to_added) > single_occlusion_px_size * min_area_threshold:
    #             all_occlusion_mask += new_occlusion  # only add occlusion if overlap smaller than threshold
    #             occlusions_added += 1
    #         i += 1
    #         if occlusions_added >= num_occlusions:
    #             break
    #         if i >= max_iterations:
    #             print(f'max number of iterations reached. Only {occlusions_added} out of {num_occlusions} have been'
    #                   f' added.')
    #             break
    #     occlusion_synthetic_only = np.logical_and(all_occlusion_mask, ~real_occlusion)
    #     pxs_occluded_synthetic = np.count_nonzero(occlusion_synthetic_only)
    #     print(
    #         f'{pxs_occluded_synthetic} ({pxs_occluded_synthetic / (real_occlusion.shape[0] * real_occlusion.shape[1] / 100):.3f}%)'
    #         f' pixels are artificially occluded')
    #     self.synthetic_occlusion = all_occlusion_mask.copy()
    #     self.occluded_target = self.target.copy()
    #     self.occluded_target[all_occlusion_mask] = 0
    #     return occlusion_synthetic_only

    # def add_existing_occlusion(self, occlusion_path):
    #     """
    #     To be used in evaluation mode only. Adds an existing randomly generated occlusion bitmap. Such occlusion mask
    #     must be generated via self.add_occlusion_mask().
    #     :param occlusion_path:
    #     :return:
    #     """
    #     if self.target_valid_mask is None:
    #         self.target_valid_mask = self.build_valid_mask()
    #     real_occlusion = ~self.target_valid_mask.copy()
    #     all_occlusion_mask = real_occlusion.copy()  # np.bool
    #
    #     occlusion_synthetic_only = np.load(occlusion_path)
    #     assert occlusion_synthetic_only is not None
    #     pxs_occluded_synthetic = np.count_nonzero(occlusion_synthetic_only)
    #     print(
    #         f'{pxs_occluded_synthetic} ({pxs_occluded_synthetic / (real_occlusion.shape[0] * real_occlusion.shape[1] / 100):.3f}%)'
    #         f' pixels are artificially occluded')
    #     all_occlusion_mask += occlusion_synthetic_only
    #     self.synthetic_occlusion = all_occlusion_mask.copy()
    #     self.occluded_target = self.target.copy()
    #     self.occluded_target[all_occlusion_mask] = 0
    #     return occlusion_synthetic_only

    # def calc_loss_hybrid(self, metric, synthetic_only_mask):
    #     """
    #     Calculate loss while expecting the reconstruction contains hybrid occlusions,
    #     both real and synthetic
    #     :param metric: mae, mse, rmse, mape
    #     :param synthetic_only_mask:
    #     :return: loss and if mae loss is specified, error_map
    #     """
    #     if self.reconstructed_target is None:
    #         raise AttributeError('Reconstruction image does not exist')
    #     a, b = self.target, self.reconstructed_target
    #     if metric == "mae":
    #         error_map = np.abs(a - b)
    #     elif metric == 'mse':
    #         error_map = np.square(a - b)
    #     elif metric == 'rmse':
    #         error_map = np.square(a - b)
    #     elif metric == 'mape':
    #         error_map = np.abs(a - b)
    #         error_map = error_map / a
    #     else:
    #         raise AttributeError(f'Unknown loss function encountered: {metric}.')
    #
    #     error_map[~synthetic_only_mask] = 0
    #     loss = np.sum(error_map) / np.count_nonzero(synthetic_only_mask)
    #     if metric == 'rmse':
    #         loss = np.sqrt(loss)
    #     if metric != 'mae':
    #         error_map = None
    #     return loss, error_map

    # def save_timelapse_frame(self, suffix=''):
    #     suffix = f'_{suffix}' if suffix != '' else ''
    #     if self.reconstructed_target is None:
    #         raise ValueError('Reconstruction result does not exist. Cannot save image output')
    #     try:
    #         # save image output
    #         img = self.reconstructed_target.copy()
    #         output_filename = f'reconst_{self.target_date}{suffix}'
    #         np.save(p.join(self.output_path, output_filename), img)
    #         output_vmin = 270
    #         output_vmax = 330
    #         plt.imshow(img, cmap='magma', vmax=output_vmax, vmin=output_vmin)
    #         plt.title(f'Reconstructed Brightness Temperature on {self.target_date}')
    #         plt.colorbar(label='BT(Kelvin)')
    #         output_filename = f'reconst_{self.target_date}{suffix}.png'
    #         plt.savefig(p.join(self.output_path, output_filename))
    #     except ValueError as e:
    #         rprint(f'ERROR: {e}.\n Current image not saved.')
    #     plt.close()
    #     return

    # def save_error_frame(self, mask, suffix=''):
    #     suffix = f'_{suffix}' if suffix != '' else ''
    #     try:
    #         # save error map
    #         img = self.target - self.reconstructed_target
    #         img[~mask] = 0
    #         output_filename = f'error_{self.target_date}{suffix}'
    #         np.save(p.join(self.output_path, output_filename), img)
    #         error_vmin = -5
    #         error_vmax = 5
    #         plt.imshow(img, cmap='seismic', vmax=error_vmax, vmin=error_vmin)
    #         plt.title(f'Error in Brightness Temperature on {self.target_date} under synthetic occlusions only')
    #         plt.colorbar(label='BT(Kelvin)')
    #         output_filename = f'error_{self.target_date}{suffix}.png'
    #         plt.savefig(p.join(self.output_path, output_filename))
    #     except ValueError as e:
    #         rprint(f'ERROR: {e}.\n Current error map not saved.')
    #     plt.close()
